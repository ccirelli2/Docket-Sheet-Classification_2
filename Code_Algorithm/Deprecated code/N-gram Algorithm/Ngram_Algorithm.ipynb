{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import os\n",
    "import string\n",
    "from nltk import corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Personal Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\Chris.Cirelli\\\\Desktop\\\\Python Programming Docs\\\\GSU\\\\Sprint Project\\\\Docket-Sheet-Classification\\\\Modules')\n",
    "import Step1_Module as stp1m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Docket Sheet File w/ Pre-classified time periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "File = r'C:\\Users\\Chris.Cirelli\\Desktop\\Python Programming Docs\\GSU\\Sprint Project\\Docket-Sheet-Classification\\Data_Files_applicable_all_code\\DocketSheet Classification_70_02.22.2018.xlsx'\n",
    "df_docketsheet = pd.read_excel(File)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Concatenated Text File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "File = open(r'C:\\Users\\Chris.Cirelli\\Desktop\\Python Programming Docs\\GSU\\Sprint Project\\Docket-Sheet-Classification\\Data_Files_applicable_all_code\\Concatenate_DocketSheet_Text.txt.txt')\n",
    "Text = File.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate each docket sheet row, clean text and obtain bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_all_bigrams(docketsheet_dataframe):\n",
    "    '''Purpose:     To generate a list of all bigrams from each of the rows of text in the docketsheet\n",
    "       Input:       Dataframe of the docketsheet \n",
    "       Process:     Iterate over each row, clean and tokenize text, generate bigrams, append bigrams to a list, \n",
    "       Output:      Return a set of the bigram list to the user. \n",
    "    '''\n",
    "    # Create a list to catch the bigrams\n",
    "    List_all_bigrams = []\n",
    "    \n",
    "    # Iterate over the panda series 'docket_text'\n",
    "    for docket_text in df_docketsheet['docket_text']:\n",
    "        # Ensure that the row is a string and not empty or something else. \n",
    "        if isinstance(docket_text, str):\n",
    "            # Clean and tokenize the text. \n",
    "            clean_text = stp1m.clean_andTokenize_text(docket_text)\n",
    "            # Clean text returns a set, which is not subscriptable, so we need to convert it to a list to generate the\n",
    "            # bigrams. \n",
    "            clean_text_list = list(clean_text)\n",
    "            append_bigrams = [List_all_bigrams.append((x,y)) for x,y in zip(clean_text_list, clean_text_list[1:])]\n",
    "    \n",
    "    # Return to the user a set of the bigrams\n",
    "    return set(List_all_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bigram_set = get_list_all_bigrams(df_docketsheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Frequency Distribution of Bigrams For Entire Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Freq_Dist_Ngrams(Text, Ngram_selection):\n",
    "    \n",
    "    Dict_Ngram_freq_dist = {}\n",
    "\n",
    "    Clean_tokenized_text = list(stp1m.clean_andTokenize_text_return_list(Text))\n",
    "    \n",
    "    if Ngram_selection == 'Bigrams':\n",
    "        Text_bigrams = (((x,y)) for x,y in zip(Clean_tokenized_text, \n",
    "                                               Clean_tokenized_text[1:]))\n",
    "        for x in Text_bigrams:\n",
    "            Dict_Ngram_freq_dist[x] = Dict_Ngram_freq_dist.get(x, 0) + 1\n",
    "            \n",
    "    elif Ngram_selection == 'Trigrams':\n",
    "        Text_trigrams = (((x,y,z)) for x,y,z in zip(Clean_tokenized_text, \n",
    "                                                    Clean_tokenized_text[1:], \n",
    "                                                    Clean_tokenized_text[2:]))\n",
    "        for x in Text_trigrams:\n",
    "            Dict_Ngram_freq_dist[x] = Dict_Ngram_freq_dist.get(x, 0) + 1\n",
    "\n",
    "    elif Ngram_selection == 'Quadgrams':\n",
    "        Text_quadgrams = (((w,x,y,z)) for w,x,y,z in zip(Clean_tokenized_text, \n",
    "                                                    Clean_tokenized_text[1:], \n",
    "                                                    Clean_tokenized_text[2:], \n",
    "                                                    Clean_tokenized_text[3:]))\n",
    "        for x in Text_quadgrams:\n",
    "            Dict_Ngram_freq_dist[x] = Dict_Ngram_freq_dist.get(x, 0) + 1\n",
    "    \n",
    "    return Dict_Ngram_freq_dist\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bigram_freq_dist = get_Freq_Dist_Ngrams(Text, 'Bigrams')\n",
    "Trigram_freq_dist = get_Freq_Dist_Ngrams(Text, 'Trigrams')\n",
    "Quad_freq_dist = get_Freq_Dist_Ngrams(Text, 'Quadgrams')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bigram = pd.DataFrame(Bigram_freq_dist, index = [len(Bigram_freq_dist)]).transpose().reset_index()\n",
    "df_trigram = pd.DataFrame(Trigram_freq_dist, index = [len(Trigram_freq_dist)]).transpose().reset_index()\n",
    "df_quadgram = pd.DataFrame(Quad_freq_dist, index = [len(Quad_freq_dist)]).transpose().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\Chris.Cirelli\\Desktop\\Python Programming Docs\\GSU\\Sprint Project\\Docket-Sheet-Classification\\Results_Files_Bigrams')\n",
    "stp1m.write_to_excel(df_bigram, 'Docketsheet_Bigram_Freq_Dist')\n",
    "stp1m.write_to_excel(df_trigram, 'Docketsheet_Trigram_Freq_Dist')\n",
    "stp1m.write_to_excel(df_quadgram, 'Docketsheet_Quadgram_Freq_Dist')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
