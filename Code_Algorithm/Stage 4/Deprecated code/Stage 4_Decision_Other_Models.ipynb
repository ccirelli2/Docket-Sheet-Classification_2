{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "import graphviz\n",
    "from sklearn.tree import export_graphviz    \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#   Classifiers\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\Chris.Cirelli\\\\Desktop\\\\Python Programming Docs\\\\GSU\\\\Sprint Project\\\\Docket-Sheet-Classification\\\\Modules')\n",
    "import Step1_Module as stp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\\\Users\\\\Chris.Cirelli\\\\Desktop\\\\Python Programming Docs\\\\GSU\\\\Sprint Project\\\\Docket-Sheet-Classification\\\\Result_Files_Key_Word_Attempt_2')\n",
    "\n",
    "df_DAT = pd.read_excel(r'C:\\Users\\Chris.Cirelli\\Desktop\\Python Programming Docs\\GSU\\Sprint Project\\Docket-Sheet-Classification\\Result_Files_Key_Word_Attempt_2\\Data Analytics Table_WordMatch_All_Docket_Entries_v4_03.10.2018.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reset_index = df_DAT.reset_index()\n",
    "df_drop_col1 = df_reset_index.drop('index', axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature = df_drop_col1.drop('Life Cycle Stage', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target = df_drop_col1['Life Cycle Stage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Simple Decision Tree\n",
    "\n",
    "def simple_decision_tree(Features, Targets):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(Features, Targets, test_size=0.2, random_state = 50)\n",
    "    clf = DecisionTreeClassifier(max_depth = 200)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    #   Train\n",
    "    clf_pred = clf.predict(X_train)\n",
    "    report_train = sklearn.metrics.classification_report(y_train, clf_pred)\n",
    "    matrix_train = sklearn.metrics.confusion_matrix(y_train, clf_pred)\n",
    "    \n",
    "    #   Test\n",
    "    clf_pred = clf.predict(X_test)\n",
    "    report_test = sklearn.metrics.classification_report(y_test, clf_pred)\n",
    "    matrix_test = sklearn.metrics.confusion_matrix(y_test, clf_pred)\n",
    "    \n",
    "    print('Report Train', '\\n', report_train, '\\n')\n",
    "    print('Report Train', '\\n', report_test, '\\n')\n",
    "    \n",
    "    return None    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report Train \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.94      0.98      0.96        87\n",
      "          2       0.98      1.00      0.99        91\n",
      "          3       0.91      0.88      0.90        73\n",
      "          4       0.76      0.90      0.83        42\n",
      "          5       0.96      0.99      0.97       488\n",
      "          6       1.00      0.89      0.94        57\n",
      "          7       0.92      0.93      0.93        61\n",
      "          8       0.94      0.72      0.81        64\n",
      "          9       1.00      1.00      1.00         2\n",
      "         10       1.00      0.97      0.98        30\n",
      "         11       1.00      0.98      0.99        41\n",
      "\n",
      "avg / total       0.95      0.95      0.95      1036\n",
      " \n",
      "\n",
      "Report Train \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.95      0.87        21\n",
      "          2       0.93      0.89      0.91        28\n",
      "          3       0.52      0.50      0.51        26\n",
      "          4       0.30      0.19      0.23        16\n",
      "          5       0.90      0.94      0.92       106\n",
      "          6       0.73      0.50      0.59        16\n",
      "          7       0.61      0.85      0.71        13\n",
      "          8       0.27      0.27      0.27        15\n",
      "         10       1.00      0.86      0.92         7\n",
      "         11       1.00      1.00      1.00        11\n",
      "\n",
      "avg / total       0.76      0.78      0.77       259\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "simple_decision_tree(df_feature, df_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Gaussian_NB(Feature, Target, Score, TestTrain):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(Feature,\n",
    "                                                        Target, \n",
    "                                                        stratify = Target, \n",
    "                                                        random_state = 50)\n",
    "    clf_NB = GaussianNB()\n",
    "    clf_NB.fit(X_train, y_train)\n",
    "    \n",
    "    clf_NB_pred_train = clf_NB.predict(X_train)\n",
    "    clf_NB_pred_test = clf_NB.predict(X_test)\n",
    "        \n",
    "    if Score == 'Classification_Report':\n",
    "        if TestTrain == 'Train':\n",
    "            report_train = sklearn.metrics.classification_report(y_train, clf_NB_pred_train)\n",
    "            print('Training Results')\n",
    "            print(report_train)\n",
    "        elif TestTrain == 'Test':\n",
    "            report_test = sklearn.metrics.classification_report(y_test, clf_NB_pred_test)\n",
    "            print('Test Results')\n",
    "            print(report_test)\n",
    "        \n",
    "    elif Score == 'Recall_Score':\n",
    "        if TestTrain == 'Train':\n",
    "            recall_train = sklearn.metrics.recall_score(y_train, clf_NB_pred_train)\n",
    "            return '{:.3f}'.format(recall_train)\n",
    "        elif TestTrain == 'Test':\n",
    "            recall_test = sklearn.metrics.recall_score(y_test, clf_NB_pred_test)\n",
    "            return '{:.3f}'.format(recall_test)\n",
    "\n",
    "    elif Score == 'Accuracy':\n",
    "        if TestTrain == 'Train':\n",
    "            recall_train = sklearn.metrics.accuracy_score(y_train, clf_NB_pred_train)\n",
    "            return '{:.3f}'.format(recall_train)\n",
    "        elif TestTrain == 'Test':\n",
    "            recall_test = sklearn.metrics.accuracy_score(y_test, clf_NB_pred_test)\n",
    "            return '{:.3f}'.format(recall_test)\n",
    "    #   END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.74      0.61        27\n",
      "          2       0.35      0.83      0.50        30\n",
      "          3       0.67      0.40      0.50        25\n",
      "          4       0.24      0.93      0.38        14\n",
      "          5       0.77      0.15      0.26       149\n",
      "          6       0.81      0.72      0.76        18\n",
      "          7       0.40      0.42      0.41        19\n",
      "          8       0.21      0.25      0.23        20\n",
      "         10       0.17      0.78      0.27         9\n",
      "         11       1.00      0.92      0.96        13\n",
      "\n",
      "avg / total       0.62      0.42      0.40       324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Gaussian_NB(df_feature, df_target, 'Classification_Report', 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Original Tree\n",
    "\n",
    "#   Tree Using GridSearchCV\n",
    "def tree_I_GridSearchCV(Features, Targets):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(Features, Targets, \n",
    "                                                        test_size=0.3, \n",
    "                                                        random_state = 100, \n",
    "                                                        stratify = Targets)\n",
    "    param_grid = {'max_depth': [2,4,6,8,10], \n",
    "                  'min_samples_split':[25,30,35], \n",
    "                  'min_samples_leaf': [25,30,35], \n",
    "                  'min_weight_fraction_leaf': [.01, .025, .05], \n",
    "                  'max_features':[2,3,4], \n",
    "                  'max_leaf_nodes':[15,20,25], \n",
    "                 }\n",
    "    tree = DecisionTreeClassifier()\n",
    "    grid_search = GridSearchCV(tree, param_grid, scoring = 'accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    prediction = grid_search.predict(X_train)\n",
    "    best_params = grid_search.best_params_\n",
    "    print(best_params)\n",
    "    class_report = sklearn.metrics.classification_report(y_train, prediction)\n",
    "    print(class_report)\n",
    "    prediction = tree.predict(X_train)\n",
    "    class_report = sklearn.metrics.classification_report(y_train, prediction)\n",
    "    print(class_report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chris.Cirelli\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:581: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 10, 'max_features': 4, 'max_leaf_nodes': 20, 'min_samples_leaf': 25, 'min_samples_split': 35, 'min_weight_fraction_leaf': 0.01}\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.63      0.71        76\n",
      "          2       0.66      0.78      0.71        83\n",
      "          3       0.00      0.00      0.00        69\n",
      "          4       0.00      0.00      0.00        41\n",
      "          5       0.62      0.92      0.74       416\n",
      "          6       0.39      0.96      0.55        51\n",
      "          7       0.00      0.00      0.00        52\n",
      "          8       0.00      0.00      0.00        55\n",
      "          9       0.00      0.00      0.00         1\n",
      "         10       0.00      0.00      0.00        26\n",
      "         11       0.00      0.00      0.00        36\n",
      "\n",
      "avg / total       0.43      0.60      0.49       906\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chris.Cirelli\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "Estimator not fitted, call `fit` before exploiting the model.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-4fa86b73cc06>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtree_I_GridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_feature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_target\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-31-3a38b80ac525>\u001b[0m in \u001b[0;36mtree_I_GridSearchCV\u001b[1;34m(Features, Targets)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mclass_report\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_report\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m     \u001b[0mclass_report\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_report\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Chris.Cirelli\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    402\u001b[0m         \"\"\"\n\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 404\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    405\u001b[0m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Chris.Cirelli\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    359\u001b[0m         \u001b[1;34m\"\"\"Validate X whenever one tries to predict, apply, predict_proba\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 361\u001b[1;33m             raise NotFittedError(\"Estimator not fitted, \"\n\u001b[0m\u001b[0;32m    362\u001b[0m                                  \"call `fit` before exploiting the model.\")\n\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFittedError\u001b[0m: Estimator not fitted, call `fit` before exploiting the model."
     ]
    }
   ],
   "source": [
    "tree_I_GridSearchCV(df_feature, df_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Best Fit to Recall - Issue.  it is fitting recall very high for the non-claims, but still very low for teh actual claims.  See if you can run this for precision to get a better score. '"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#    Test GridSearchCV Tree on test subjects\n",
    "def tree_I_best_fit(Features, Targets):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(Features, Targets, test_size=0.3, random_state = 100, stratify = Targets)\n",
    "    tree = DecisionTreeClassifier(max_depth= 4, \n",
    "                                  max_features= 4, \n",
    "                                  max_leaf_nodes = 20, \n",
    "                                  min_samples_leaf= 25, \n",
    "                                  min_samples_split = 35, \n",
    "                                  min_weight_fraction_leaf = 0.01)\n",
    "    tree.fit(X_train, y_train)   \n",
    "    \n",
    "    #prediction_train = tree.predict(X_train)\n",
    "    #class_report_train = sklearn.metrics.classification_report(y_train, prediction_train)\n",
    "    #print(class_report_train)\n",
    "    prediction_test = tree.predict(X_test)\n",
    "    class_report_test = sklearn.metrics.classification_report(y_test, prediction_test)\n",
    "    print(class_report_test)\n",
    "\n",
    "'''Best Fit to Recall - Issue.  it is fitting recall very high for the non-claims, but still very low for teh actual claims.  See if you can run this for precision to get a better score. '''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.84      0.50      0.63        32\n",
      "          2       0.74      0.47      0.58        36\n",
      "          3       0.00      0.00      0.00        30\n",
      "          4       0.00      0.00      0.00        17\n",
      "          5       0.51      1.00      0.68       178\n",
      "          6       0.00      0.00      0.00        22\n",
      "          7       0.00      0.00      0.00        22\n",
      "          8       0.00      0.00      0.00        24\n",
      "          9       0.00      0.00      0.00         1\n",
      "         10       0.00      0.00      0.00        11\n",
      "         11       0.00      0.00      0.00        16\n",
      "\n",
      "avg / total       0.37      0.54      0.42       389\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chris.Cirelli\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "tree_I_best_fit(df_feature, df_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#   Original Random Tree\n",
    "def random_tree_I(Features, Targets):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(Features, Targets, test_size = 0.3, random_state = 50)\n",
    "    forest = RandomForestClassifier(n_estimators = 100, max_depth = 55, min_samples_split = 2, max_features = 4, min_samples_leaf = 1, min_impurity_split = .03)\n",
    "    forest.fit(X_train, y_train)\n",
    "    prediction_train = forest.predict(X_train)\n",
    "    recall_score_train = sklearn.metrics.classification_report(y_train, prediction_train)\n",
    "    prediction_test = forest.predict(X_test)\n",
    "    recall_score_test = sklearn.metrics.classification_report(y_test, prediction_test)\n",
    "    print('Recall score train => ', recall_score_train)\n",
    "    print('')\n",
    "    print('Recall score test => ', recall_score_test)\n",
    "        \n",
    "#   Best fit Random Tree\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall score train =>               precision    recall  f1-score   support\n",
      "\n",
      "          1       1.00      1.00      1.00        76\n",
      "          2       1.00      0.99      0.99        81\n",
      "          3       1.00      0.97      0.98        65\n",
      "          4       0.92      0.95      0.93        37\n",
      "          5       1.00      1.00      1.00       423\n",
      "          6       1.00      1.00      1.00        51\n",
      "          7       0.98      0.96      0.97        51\n",
      "          8       0.93      0.96      0.94        52\n",
      "          9       1.00      1.00      1.00         2\n",
      "         10       1.00      1.00      1.00        29\n",
      "         11       1.00      1.00      1.00        39\n",
      "\n",
      "avg / total       0.99      0.99      0.99       906\n",
      "\n",
      "\n",
      "Recall score test =>               precision    recall  f1-score   support\n",
      "\n",
      "          1       0.97      0.91      0.94        32\n",
      "          2       0.94      0.89      0.92        38\n",
      "          3       0.85      0.65      0.73        34\n",
      "          4       0.29      0.33      0.31        21\n",
      "          5       0.94      0.98      0.96       171\n",
      "          6       0.83      0.91      0.87        22\n",
      "          7       0.79      0.83      0.81        23\n",
      "          8       0.52      0.56      0.54        27\n",
      "         10       1.00      0.75      0.86         8\n",
      "         11       1.00      0.92      0.96        13\n",
      "\n",
      "avg / total       0.86      0.85      0.85       389\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_tree_I(df_feature, df_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Example of Bagging\n",
    "    \n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "#from sklear.tree import DecisionTreeClassifier\n",
    "\n",
    "def decision_tree_baggin(Features, Targets):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(Features, Targets, test_size = 0.3)\n",
    "    bag_clf = BaggingClassifier(\n",
    "            n_estimators = 5,                      #train 500 different Decision Tree Classifiers. \n",
    "            max_samples = 200, \n",
    "            bootstrap = True, \n",
    "            n_jobs = -1)                            #number of classifiers to run at the same time.  If -1, then num jobs = num cores. \n",
    "\n",
    "    bag_clf.fit(X_train, y_train)\n",
    "    y_pred = bag_clf.predict(X_test)\n",
    "    score = sklearn.metrics.accuracy_score(y_test, y_pred)\n",
    "    print(score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bagger(Features, Targets):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(Features, Targets)\n",
    "    bg = BaggingClassifier(\n",
    "            RandomForestClassifier(),\n",
    "            max_samples = 2000, \n",
    "            max_features = 3, \n",
    "            n_estimators = 100)\n",
    "    bg.fit(X_train, y_train)\n",
    "    prediction = bg.predict(X_test)\n",
    "    score = sklearn.metrics.classification_report(y_test, prediction)\n",
    "    print(score)\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Booster(Features, Targets):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(Features, Targets)    \n",
    "    ada_clf = AdaBoostClassifier(\n",
    "            DecisionTreeClassifier(max_depth= 8, \n",
    "                                  max_features= 4, \n",
    "                                  max_leaf_nodes = 20, \n",
    "                                  min_samples_leaf= 25, \n",
    "                                  min_samples_split = 35, \n",
    "                                  min_weight_fraction_leaf = 0.01),\n",
    "            n_estimators = 200)\n",
    "    ada_clf.fit(X_train, y_train)\n",
    "    #prediction = ada_clf.predict((X_train))\n",
    "    #score = sklearn.metrics.classification_report(y_train, prediction)\n",
    "    prediction = ada_clf.predict((X_test))\n",
    "    score = sklearn.metrics.classification_report(y_test, prediction)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.40      0.79      0.53        28\n",
      "          2       0.64      0.29      0.40        31\n",
      "          3       0.54      0.54      0.54        26\n",
      "          4       0.33      0.33      0.33        12\n",
      "          5       0.84      0.78      0.81       150\n",
      "          6       0.71      0.56      0.63        18\n",
      "          7       0.17      0.26      0.20        19\n",
      "          8       0.19      0.18      0.18        17\n",
      "         10       1.00      0.44      0.62         9\n",
      "         11       1.00      1.00      1.00        14\n",
      "\n",
      "avg / total       0.67      0.62      0.63       324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Booster(df_feature, df_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DecisionTreeRegressor_Boost(Features, Targets):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(Features, Targets)  \n",
    "    tree_reg1 = DecisionTreeRegressor()\n",
    "    tree_reg1.fit(X_train, y_train)   \n",
    "    prediction = tree_reg1.predict(X_train)\n",
    "    report = sklearn.metrics.classification_report(y_train, prediction)\n",
    "    return report\n",
    "     \n",
    "report = DecisionTreeRegressor(df_feature, df_target)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
