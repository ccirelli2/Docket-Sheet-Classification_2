{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "import graphviz\n",
    "from sklearn.tree import export_graphviz    \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "#   Classifiers\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir(r'/home/ccirelli2/Desktop/Docket-Sheet-Classification/Modules')\n",
    "import Step4_Module_Machine_Learning_Algorithms as stp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MAKE PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_predictions_decisionTree(Target_dir, Depth = 8, KeyWord = 'Nograms', Write2Excel = False, \n",
    "                                  Destination_location = None, Iterable = True, Single_File = None, \n",
    "                                  Metric = 'Accuracy', TestTrain = None):\n",
    "    '''Documentation\n",
    "    \n",
    "    Input:      i.)    Target_dir  = location where our docketsheet key word appearance dataframes are located. \n",
    "                ii.)   Depth       = the depth that we want to use for our tree.  If not specified default \n",
    "                                     to 8. \n",
    "                iii.)  Write2Excel = if we want to write to Excel or work with the results in memory. \n",
    "                                     this feature is not yet set up for the confusion matrix or class report. \n",
    "                iv.)   Destination = where we want to write our results to. \n",
    "                v.)    Iterable    = whether we are working with a single or multiple files. \n",
    "                vi.)   Single_file = if we chose False for the Iterable, then we will need to specify the \n",
    "                                     file we want to use. \n",
    "                vii.)  Metric      = the metric that we want to use to guage the performance of our model. \n",
    "                                     default to 'Accuracy'.  Can also chose 'Matrix' to return the confusion\n",
    "                                     matrix. \n",
    "                viii.) KeyWord     = Choose the key word that you want to use to group the files (approachs)\n",
    "                                     to be used in the ML model. Examples include using the names of the \n",
    "                                     ngrmas ('Bigrams') or it could be STDV vs COCOEF, etc. \n",
    "                                     \n",
    "    Operations i.)     The main operation here is either to iterate a list of files in a directory to \n",
    "                       generate the predictions or to work with one file.  That and the code is set up so \n",
    "                       that the user can have various choices as can be inferred from the input explanations. \n",
    "                       \n",
    "    '''\n",
    "    # Dictionary to house values\n",
    "    Dict = {}\n",
    "\n",
    "    # Change Directory\n",
    "    os.chdir(Target_dir)\n",
    "    \n",
    "    # If you are looking to iterate over an entire directory of files\n",
    "    if Iterable == True:\n",
    "    \n",
    "        #Loop over files\n",
    "        for file in os.listdir():\n",
    "        \n",
    "            # Choose the key word to group the files that are chosen by the code.  \n",
    "            if KeyWord in file:\n",
    "                # Mark start of process\n",
    "                print('Generating prediction for =>', '\\n', file, '\\n')\n",
    "                # Create the Feature & Target dataframes. \n",
    "                Features = stp4.get_feature_target_dataframes(file, dataset = 'Features')\n",
    "                Targets  = stp4.get_feature_target_dataframes(file, dataset = 'Targets')\n",
    "                # Generate The Training Results\n",
    "                Accuracy_train = stp4.simple_decision_tree(Features, Targets, \n",
    "                                                  Max_Depth = Depth, TrainTest = 'Train', \n",
    "                                                  Metric = Metric)\n",
    "                # Generate the Test Results. \n",
    "                Accuracy_test = stp4.simple_decision_tree(Features, Targets, \n",
    "                                                  Max_Depth = Depth, TrainTest = 'Test', \n",
    "                                                  Metric = Metric)\n",
    "            \n",
    "                # Add your results to the dictionary object using file name as the key. \n",
    "                Dict[file] = (Accuracy_train, Accuracy_test)\n",
    "    \n",
    "    # If the user only wants to work with one file. \n",
    "    elif Iterable == False:\n",
    "        \n",
    "        # Mark start of process\n",
    "        print('Generating prediction for =>', '\\n', Single_File, '\\n')\n",
    "        # Get Features & Targets\n",
    "        Features = stp4.get_feature_target_dataframes(Single_File, dataset = 'Features')\n",
    "        Targets  = stp4.get_feature_target_dataframes(Single_File, dataset = 'Targets')\n",
    "        # Generate Prediction\n",
    "        Accuracy_train = simple_decision_tree(Features, Targets, \n",
    "                                                  Max_Depth = Depth, TrainTest = 'Train', \n",
    "                                                  Metric = Metric)\n",
    "        Accuracy_test = simple_decision_tree(Features, Targets, \n",
    "                                                  Max_Depth = Depth, TrainTest = 'Test', \n",
    "                                                  Metric = Metric)\n",
    "        # Append results to a dictionary object. \n",
    "        Dict[Single_File] = (Accuracy_train, Accuracy_test)\n",
    "\n",
    "    # Create Dataframe from dictionary object. \n",
    "    df = pd.DataFrame(Dict)\n",
    "    df_transpose = df.transpose()\n",
    "    # Define the column names.  In the future, if we add more measures, we can change this. \n",
    "    df_rename_cols = df_transpose.rename(index = str, columns = {0: 'Accuracy_train', \n",
    "                                                                 1: 'Accuracy_test'}) \n",
    "    df_final = df_rename_cols.sort_values(by = 'Accuracy_test', ascending = False)\n",
    "    \n",
    "    # Write to Excel\n",
    "    if Write2Excel == True:\n",
    "        print('Writing dataframe to Excel')\n",
    "        os.chdir(Destination_location)\n",
    "        File_name = 'Decision Tree Results for' + '_' + Ngram\n",
    "        print('File name => ' + File_name)\n",
    "        stp4.write_to_excel(df_final, Destination_location, File_name)\n",
    "        print('Your file has been saved to =>  ', Destination_location, '\\n', '\\n')\n",
    "    # If the user does not want to write to Excel return to them the dataframe in memory.     \n",
    "    else:    \n",
    "        print('Results', '\\n', df_final)\n",
    "        return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# WORKING WITH SINGLE FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating prediction for => \n",
      " DocketSheet_WordMatches_TopWords_Bigrams_CalculationI_homebrew_STDV_Top15_highest_STDV.xlsx.xlsx \n",
      "\n"
     ]
    }
   ],
   "source": [
    "Target_dir = r'/home/ccirelli2/Desktop/Docket-Sheet-Classification/Results_Docketsheet_wordMatches'\n",
    "Destination = r'/home/ccirelli2/Desktop/Docket-Sheet-Classification/Results_ML_Models'\n",
    "Ngram_options = ['Nograms', 'Bigrams', 'Trigrams', 'Quadgrams']\n",
    "MaxDepth = [10,20,30,40,50,60,70,80,90,100]\n",
    "\n",
    "df_prediction = make_predictions_decisionTree(Target_dir, \n",
    "                                            Depth = depth, \n",
    "                                            Ngram = 'Nograms',\n",
    "                                            Iterable = False, \n",
    "                                            Single_File = 'DocketSheet_WordMatches_TopWords_Bigrams_CalculationI_homebrew_STDV_Top15_highest_STDV.xlsx.xlsx',\n",
    "                                            Metric = 'Accuracy',\n",
    "                                            Write2Excel = False, \n",
    "                                            Destination_location = Destination)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WORKING WITH MULTIPLE FILES IN A DIRECTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating prediction for => \n",
      " DocketSheet_WordMatches_TopWords_Nograms_CalculationII_AVG_not_zero_Top15_highest_STDV.xlsx.xlsx \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ccirelli2/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating prediction for => \n",
      " DocketSheet_WordMatches_TopWords_Nograms_CalculationIII_Correlation_Coefficient_Top15_highest_COCOEF.xlsx.xlsx \n",
      "\n",
      "Generating prediction for => \n",
      " DocketSheet_WordMatches_TopWords_Nograms_CalculationI_homebrew_STDV_Top15_highest_STDV.xlsx.xlsx \n",
      "\n",
      "Results \n",
      "                                                     Accuracy_train  \\\n",
      "DocketSheet_WordMatches_TopWords_Nograms_Calcul...            0.99   \n",
      "DocketSheet_WordMatches_TopWords_Nograms_Calcul...            0.98   \n",
      "DocketSheet_WordMatches_TopWords_Nograms_Calcul...            0.98   \n",
      "\n",
      "                                                    Accuracy_test  \n",
      "DocketSheet_WordMatches_TopWords_Nograms_Calcul...           0.86  \n",
      "DocketSheet_WordMatches_TopWords_Nograms_Calcul...           0.85  \n",
      "DocketSheet_WordMatches_TopWords_Nograms_Calcul...           0.83  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ccirelli2/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "Target_dir = r'/home/ccirelli2/Desktop/DocketsheetDistResults'\n",
    "Destination = r'/home/ccirelli2/Desktop/Docket-Sheet-Classification/Results_ML_Models'\n",
    "\n",
    "df_prediction = make_predictions_decisionTree(Target_dir, \n",
    "                                            Depth = 35,\n",
    "                                            KeyWord = 'Nograms', \n",
    "                                            Iterable = True, \n",
    "                                            Metric = 'Accuracy',\n",
    "                                            Write2Excel = False, \n",
    "                                            Destination_location = Destination, \n",
    "                                            TestTrain = 'Test')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"OBSERVATIONS\\n\\nFeature_selection:      A depth of 30 appears to provide the best results. \\nPrecision & Recall:     The best so far as been .89 and .88. \\nStages:                 Stage 4 and 8 continue to perform the worst. \\nStage4:                 Incorrectly predicts stages 7 and 8.\\n                        Overlap:  only 1 word overlaps Stages 4 and 7 'Civil'. \\nStage8:                 Incorrectly predicts 4 and 5. \\n                        Overlap:  There is significant overlap between 8 and 4. Three words overlap in Word Group 2, which \\n                        is where the AVG is between 1-2% and CV is the highest. Two words overlap in Word Group 3, which \\n                        is our contrarian word group. \\n\\nOverall                 VAR is not a good measurement for identifying the top 5 words for our stage 1 and 2 as it removes\\n                        the sign from our frequencies such that a word with a large negative deviation could get put into\\n                        this group.  If we were only grabbing the top 15 words using VAT and or STDV we would probably be \\n                        ok.  \\n                        AVG of all other time periods runs into issues as many of the columns may have a 0% but others \\n                        could have a frequency at or higher than our target time period.  Therefore, we might think about\\n                        eliminating the columns with 0% when calculating our average.  This would force the code to \\n                        recognize a higher average for the other time periods. \\n\\nThoughts:               1.) Amend the Top5 selection code to calculate the AVG not using any of the Stages with 0%. \\n                        2.) Revert back to the old calculation which was ((Target/Avg)*Target) as it is sign sensitive    \\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''OBSERVATIONS\n",
    "\n",
    "Feature_selection:      A depth of 30 appears to provide the best results. \n",
    "Precision & Recall:     The best so far as been .89 and .88. \n",
    "Stages:                 Stage 4 and 8 continue to perform the worst. \n",
    "Stage4:                 Incorrectly predicts stages 7 and 8.\n",
    "                        Overlap:  only 1 word overlaps Stages 4 and 7 'Civil'. \n",
    "Stage8:                 Incorrectly predicts 4 and 5. \n",
    "                        Overlap:  There is significant overlap between 8 and 4. Three words overlap in Word Group 2, which \n",
    "                        is where the AVG is between 1-2% and CV is the highest. Two words overlap in Word Group 3, which \n",
    "                        is our contrarian word group. \n",
    "\n",
    "Overall                 VAR is not a good measurement for identifying the top 5 words for our stage 1 and 2 as it removes\n",
    "                        the sign from our frequencies such that a word with a large negative deviation could get put into\n",
    "                        this group.  If we were only grabbing the top 15 words using VAT and or STDV we would probably be \n",
    "                        ok.  \n",
    "                        AVG of all other time periods runs into issues as many of the columns may have a 0% but others \n",
    "                        could have a frequency at or higher than our target time period.  Therefore, we might think about\n",
    "                        eliminating the columns with 0% when calculating our average.  This would force the code to \n",
    "                        recognize a higher average for the other time periods. \n",
    "\n",
    "Thoughts:               1.) Amend the Top5 selection code to calculate the AVG not using any of the Stages with 0%. \n",
    "                        2.) Revert back to the old calculation which was ((Target/Avg)*Target) as it is sign sensitive    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
