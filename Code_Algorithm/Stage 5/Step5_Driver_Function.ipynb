{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Next Steps 04.02.2018\\n\\nDecision Tree:\\n- A conditional statement needs to be added to the Feature/Target objects.  \\n- If Prediction_type = Known_dataset, then use the current set up.\\n- else: \\n- X_test will need to be replaced with the features from our unknown dataset (the master docketsheet)\\n- So we'll need to drop the first and last columns.  \\n- The function should then return a dataframe with the correction predictions. \\n\\nAlso:\\n- We need to create an option in the code to include or not include the Dataframe_test.  \\n- This will need to be linked to the above decision tree conditional statement. \\n- This way we can have an option to train the model and once we get the best set of hyperparameters\\nrun the model to make a prediction on the unknown dataset. \\n\\nQuestion:\\n- How do we set up our code such that we only run stp3B when we want to?\\n\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Next Steps 04.02.2018\n",
    "\n",
    "Decision Tree:\n",
    "- A conditional statement needs to be added to the Feature/Target objects.  \n",
    "- If Prediction_type = Known_dataset, then use the current set up.\n",
    "- else: \n",
    "- X_test will need to be replaced with the features from our unknown dataset (the master docketsheet)\n",
    "- So we'll need to drop the first and last columns.  \n",
    "- The function should then return a dataframe with the correction predictions. \n",
    "\n",
    "Also:\n",
    "- We need to create an option in the code to include or not include the Dataframe_test.  \n",
    "- This will need to be linked to the above decision tree conditional statement. \n",
    "- This way we can have an option to train the model and once we get the best set of hyperparameters\n",
    "run the model to make a prediction on the unknown dataset. \n",
    "\n",
    "Question:\n",
    "- How do we set up our code such that we only run stp3B when we want to?\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IMPORT MODULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir(r'/home/ccirelli2/Desktop/GSU/Docket-Sheet-Classification-v2/Modules')\n",
    "import Step1_Module_Ngrams_FreqDist_version4_Ngrams as stp1\n",
    "import Step2_P2_Module_Get_Top_Words_version4_Ngrams as stp2\n",
    "import Step3_Module_Ngrams_Docketsheet_KeyWord_FreqDist as stp3\n",
    "import Step4_Module_Machine_Learning_Algorithms as stp4\n",
    "import Step5_Module_Measure_DocketSheetEntries_NoMatches as stp5_nomatch\n",
    "import Step5_Module_Measure_Dependencies_Between_Stages as stp5_dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IMPORT NGRAM RESULTS:  CALCULATION = AVERAGE APPEARANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir(r'/home/ccirelli2/Desktop/GSU/Docket-Sheet-Classification-v2/Docket_Sheet_Classification_DataFiles_Stage2/Ngram_Frequencies')\n",
    "Nograms_appearance = pd.read_excel(r'Docketsheet_FreqDist_Nograms_Average_appearance.xlsx')\n",
    "Bigrams_appearance = pd.read_excel(r'Docketsheet_FreqDist_Bigrams_Average_appearance.xlsx')\n",
    "Trigrams_appearance = pd.read_excel(r'Docketsheet_FreqDist_Trigrams_Average_appearance.xlsx')\n",
    "Quadgrams_appearance = pd.read_excel(r'Docketsheet_FreqDist_Quadgrams_Average_appearance.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IMPORT NGRAM RESULTS:  CALCULATION = FREQUENCY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Nograms_frequency = pd.read_excel(r'Docketsheet_FreqDist_Nograms_Frequency_distribution.xlsx')\n",
    "Bigrams_frequency = pd.read_excel(r'Docketsheet_FreqDist_Bigrams_Frequency_distribution.xlsx')\n",
    "Trigrams_frequency = pd.read_excel(r'Docketsheet_FreqDist_Trigrams_Frequency_distribution.xlsx')\n",
    "Quadgrams_frequency = pd.read_excel(r'Docketsheet_FreqDist_Quadgrams_Frequency_distribution.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IMPORT DOCKETSHEET WITH PRE-CLASSIFIED STAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "Docketsheet_train = r'/home/ccirelli2/Desktop/GSU/Docket-Sheet-Classification-v2/Docket_Sheet_Classification_DataFiles_Stage2/Docket_Sheet_Entries/Pre-Classified_TimePeriods.xlsx'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IMPORT MASTER DOCKETSHEET WITH NON-CLASSIFIED STAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Only run the below code if the document has yet to be created.  Otherwise, just import the file. \n",
    "'''\n",
    "File_masterdocketsheet = r'Master_Docket_sheets.xlsx'\n",
    "Destination_loc = r'/home/ccirelli2/Desktop/Docket-Sheet-Classification/Data_Files_applicable_all_code'\n",
    "df_transformed = stp3.transform_Master_Docketsheet(File_masterdocketsheet, Write2Excel =True, \n",
    "                                               destination_location = Destination_loc)\n",
    "'''\n",
    "Dir = '/home/ccirelli2/Desktop/GSU/Docket-Sheet-Classification-v2/Docket_Sheet_Classification_DataFiles_Stage2/Docket_Sheet_Entries/'\n",
    "Docketsheet_test = Dir + 'Master_Docketsheet_RelevantEntriesOnly_04.11.2018.xlsx'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CHUNK MASTER DOCKETSHEET\n",
    "def chunk_master_docketsheetfile(Excel_file):\n",
    "\n",
    "    df = pd.read_excel(Excel_file)\n",
    "    df_chunked = df.iloc[150001:200000,:]\n",
    "\n",
    "    # Write to Excel Module\n",
    "    stp4.write_to_excel(    \n",
    "                dataframe = df_chunked, \n",
    "                location = r'/home/ccirelli2/Desktop/Docket-Sheet-Classification/Stage5_Predictions_Results',\n",
    "                filename = 'Master_Docketsheet_Chunk4')\n",
    "\n",
    "    return df_chunked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DRIVER FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MasterFunction( TrainTestMode, # 04.03.2018: This refers to stp3A & B. \n",
    "    \n",
    "                    stp2_FreqDist_file, \n",
    "                        stp2_Calculation_meth, stp2_methodology_top_words, \n",
    "                        stp2_write2excel, stp2_destination_location, \n",
    "                        stp2_Ngram_type,\n",
    "                   \n",
    "                   stp3A_Docketsheet, \n",
    "                        stp3A_DirNgramLoc, stp3A_Iterable, \n",
    "                        stp3A_KeyPhrase, stp3A_Destination_location,\n",
    "                        stp3A_Transpose4mlModel, stp3A_Write2Excel,\n",
    "                   \n",
    "                   stp3B_Docketsheet, \n",
    "                        stp3B_DirNgramLoc, stp3B_Iterable, \n",
    "                        stp3B_KeyPhrase, stp3B_Destination_location,\n",
    "                        stp3B_Transpose4mlModel, stp3B_Write2Excel,\n",
    "                   \n",
    "                   stp4_Max_Depth, \n",
    "                        stp4_TrainTest, \n",
    "                        stp4_Metric):\n",
    "    \n",
    "    # BODY OF FUNCTION STARTS HERE:_____________________________________________________________________\n",
    "    \n",
    "    # STEP2: GENERATE KEY NGRAMS____________________________________________________:\n",
    "    \n",
    "    print('Step2: Generating our Key Ngrmas...\\n')\n",
    "    TopWords_Toggle_Calc_Methodology = stp2.get_top_words_toggle_methodology(\n",
    "                    # Features\n",
    "                    stp2_FreqDist_file, \n",
    "                    stp2_Calculation_meth, \n",
    "                    stp2_methodology_top_words, \n",
    "                    stp2_write2excel, \n",
    "                    stp2_destination_location, \n",
    "                    stp2_Ngram_type)\n",
    "    \n",
    "    # If writing to Excel, revert back to main dir where docketsheet is located. \n",
    "    os.chdir(r'/home/ccirelli2/Desktop/GSU/Docket-Sheet-Classification-v2/Docket_Sheet_Classification_DataFiles_Stage2/Docket_Sheet_Entries')\n",
    "    \n",
    "    \n",
    "    # STEP3_A: DOCKETSHEET NGRAM APPEARANCE - TRAINING MODE_________________________:\n",
    "    \n",
    "    # Added 04.03.2018: Toggle Between Training & Test Modes\n",
    "    if TrainTestMode == 'Training_Mode_Known_Data':\n",
    "        print('Step3_A: Generating the Ngram matches for the \\'Training\\' Docketsheet entries...\\n')\n",
    "        stp3A_KeyNgram_Appearance_Training_DocketSheetEntries = stp3.get_DocketSheet_KeyWord_Appearance_Master(\n",
    "                    # Features\n",
    "                    stp3_Docketsheet                 = stp3A_Docketsheet, \n",
    "                    stp3_DirNgramLoc                 = stp3A_DirNgramLoc, \n",
    "                    stp3_Iterable                    = stp3A_Iterable, \n",
    "                    stp3_KeyPhrase                   = stp3A_KeyPhrase, \n",
    "                    stp3_Destination_location        = stp3A_Destination_location,\n",
    "                    stp3_Transpose4mlModel           = stp3A_Transpose4mlModel, \n",
    "                    stp3_Write2Excel                 = stp3A_Write2Excel, \n",
    "                    stp3_Target_file                 = TopWords_Toggle_Calc_Methodology)\n",
    "       \n",
    "        # Step4: Decision Tree Prediction\n",
    "        print('Step4:  Generating Decision Tree prediction\\n')\n",
    "        DecisionTreePrediction = stp4.simple_decision_tree(\n",
    "                    Max_Depth                        = stp4_Max_Depth, \n",
    "                    TrainTest                        = stp4_TrainTest, \n",
    "                    Metric                           = stp4_Metric,\n",
    "                    Docketsheet_known                = stp3A_KeyNgram_Appearance_Training_DocketSheetEntries,\n",
    "                    Docketsheet_unknown              = None, # None as it will not be used in Training mode. \n",
    "                    TrainTestMode                    = TrainTestMode) #added 04.03.2018\n",
    "    \n",
    "        # Define File Name for In-Memory Reference (Not reading from a file + path name)\n",
    "        df_inmemory_name = str(stp2_Ngram_type + '_' + stp2_Calculation_meth + '_' + \n",
    "        stp2_methodology_top_words + '_' + stp4_Metric + '_' + 'Depth' + '_' + str(stp4_Max_Depth))\n",
    "    \n",
    "        # Calculate the number of docket sheet rows without a match.  Send to user via print. \n",
    "        Count_zero = stp5_nomatch.get_count_nomatch_columns(\n",
    "            File = stp3A_KeyNgram_Appearance_Training_DocketSheetEntries, Count = 'Count_zero')\n",
    "        Count_total = stp5_nomatch.get_count_nomatch_columns(\n",
    "            File = stp3A_KeyNgram_Appearance_Training_DocketSheetEntries, Count = 'Count_all')\n",
    "    \n",
    "        # Calculate the extent of dependencies between the KeyWords in Each Stage. \n",
    "        Perct_dependency = stp5_dependencies.measure_dependencies(TopWords_Toggle_Calc_Methodology)\n",
    "    \n",
    "        # OTHER PERFORMANCE METRICS REGARDING THE MODEL\n",
    "        print('Other performance metrics:')\n",
    "        print('\\tPercent Dependency:   The Ngram Key Selection resulted in =>' + ' ' + str(Perct_dependency) + ' of overlap (dependency) between the key words')\n",
    "        print('\\tPercent None-Matches: In addition, this selection resulted in => ', round(Count_zero/Count_total, 2)*100, ' ' + \n",
    "          'percentage of Docketsheet rows without a matching Ngram', '\\n')\n",
    "    \n",
    "        return DecisionTreePrediction\n",
    "    \n",
    "    \n",
    "    # STEP3 A&B - TESTING MODE________________________________________________________________\n",
    "    \n",
    "    elif TrainTestMode == 'Prediction_Mode_Unknown_Data':\n",
    "        print('Step3_A: Generating the Ngram matches for the \\'Training\\' Docketsheet entries...\\n')\n",
    "        stp3A_KeyNgram_Appearance_Training_DocketSheetEntries = stp3.get_DocketSheet_KeyWord_Appearance_Master(\n",
    "                    # Features\n",
    "                    stp3_Docketsheet                 = stp3A_Docketsheet, \n",
    "                    stp3_DirNgramLoc                 = stp3A_DirNgramLoc, \n",
    "                    stp3_Iterable                    = stp3A_Iterable, \n",
    "                    stp3_KeyPhrase                   = stp3A_KeyPhrase, \n",
    "                    stp3_Destination_location        = stp3A_Destination_location,\n",
    "                    stp3_Transpose4mlModel           = stp3A_Transpose4mlModel, \n",
    "                    stp3_Write2Excel                 = stp3A_Write2Excel, \n",
    "                    stp3_Target_file                 = TopWords_Toggle_Calc_Methodology)\n",
    "    \n",
    "        # Added on 03.31.2018:  Step_3 B was added. \n",
    "        print('Step3_B: Generating the Ngram matches for the \\'Test\\' Docketsheet entries...\\n')\n",
    "        stp3B_KeyNgram_Appearance_Test_DocketSheetEntries = stp3.get_DocketSheet_KeyWord_Appearance_Master(\n",
    "                    # Features\n",
    "                    stp3_Docketsheet                 = stp3B_Docketsheet, \n",
    "                    stp3_DirNgramLoc                 = stp3B_DirNgramLoc, \n",
    "                    stp3_Iterable                    = stp3B_Iterable, \n",
    "                    stp3_KeyPhrase                   = stp3B_KeyPhrase, \n",
    "                    stp3_Destination_location        = stp3B_Destination_location,\n",
    "                    stp3_Transpose4mlModel           = stp3B_Transpose4mlModel, \n",
    "                    stp3_Write2Excel                 = stp3B_Write2Excel, \n",
    "                    stp3_Target_file                 = TopWords_Toggle_Calc_Methodology)\n",
    "    \n",
    "        # Step4: Decision Tree Prediction\n",
    "        print('Step4:  Generating Decision Tree prediction\\n')\n",
    "        DecisionTreePrediction = stp4.simple_decision_tree(\n",
    "                    Max_Depth                        = stp4_Max_Depth, \n",
    "                    TrainTest                        = stp4_TrainTest, \n",
    "                    Metric                           = stp4_Metric,\n",
    "                    Docketsheet_known                = stp3A_KeyNgram_Appearance_Training_DocketSheetEntries,\n",
    "                    Docketsheet_unknown              = stp3B_KeyNgram_Appearance_Test_DocketSheetEntries,\n",
    "                    TrainTestMode                    = TrainTestMode) #added 04.03.2018\n",
    "       \n",
    "        return DecisionTreePrediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NOTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nNote that you the ytrain and test objects likely contain the arrays and attributes that we are calling like confusion matrix \\nand or report are likely just ways to arrange these predictions. \\n**** Note that you created a new object in Step4, the decision tree model, that allows for you to return a dataframe of the \\nindividual predictions.  This function has dependencies, in particular the second function that generates the Accuracy, \\nMatrics, etc scores.  You need to find a way to stop the second function from running and to only pass the data frame \\nobject to the user. \\n\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Note that you the ytrain and test objects likely contain the arrays and attributes that we are calling like confusion matrix \n",
    "and or report are likely just ways to arrange these predictions. \n",
    "**** Note that you created a new object in Step4, the decision tree model, that allows for you to return a dataframe of the \n",
    "individual predictions.  This function has dependencies, in particular the second function that generates the Accuracy, \n",
    "Matrics, etc scores.  You need to find a way to stop the second function from running and to only pass the data frame \n",
    "object to the user. \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RUN FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Stage2_destination_location = '/home/ccirelli2/Desktop/GSU/Docket-Sheet-Classification-v2/Docket_Sheet_Classification_DataFiles_Stage2/Key_Ngram_Selections'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step2: Generating our Key Ngrmas...\n",
      "\n",
      "@@@@ Writing Top_words_all_calcs_dataframe to Excel\n",
      "@@@@ Writing Top_words_all_calcs_dataframe to Excel\n",
      "@@@@ Writing Top_words_all_calcs_dataframe to Excel\n",
      "@@@@ Writing Top_words_all_calcs_dataframe to Excel\n",
      "@@@@ Writing Top_words_all_calcs_dataframe to Excel\n",
      "@@@@ Writing Top_words_all_calcs_dataframe to Excel\n",
      "@@@@ Writing Top_words_all_calcs_dataframe to Excel\n",
      "@@@@ Writing Top_words_all_calcs_dataframe to Excel\n",
      "@@@@ Writing Top_words_all_calcs_dataframe to Excel\n",
      "@@@@ Writing Top_words_all_calcs_dataframe to Excel\n",
      "@@@@ Writing Top_words_all_calcs_dataframe to Excel\n",
      "Writing dataframe to Excel\n",
      "File name => TopWords_Nograms_appearance_Avg_50pct_CalculationII_AVG_not_zero_Top15_highest_STDV\n",
      "Your file has been saved to:   /home/ccirelli2/Desktop/GSU/Docket-Sheet-Classification-v2/Docket_Sheet_Classification_DataFiles_Stage2/Key_Ngram_Selections \n",
      "\n",
      "Step3_A: Generating the Ngram matches for the 'Training' Docketsheet entries...\n",
      "\n",
      "\t25% completed\n",
      "\t50% completed\n",
      "\t75% completed\n",
      "\n",
      "Step4:  Generating Decision Tree prediction\n",
      "\n",
      "Returning training report:\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.98      0.98      0.98       181\n",
      "          2       0.99      0.97      0.98       115\n",
      "          3       0.90      0.95      0.93        88\n",
      "          4       0.90      0.83      0.86       116\n",
      "          5       0.98      1.00      0.99       885\n",
      "          6       1.00      1.00      1.00        93\n",
      "          7       1.00      0.87      0.93        47\n",
      "          8       0.91      0.95      0.93       105\n",
      "          9       1.00      1.00      1.00        18\n",
      "         10       1.00      0.92      0.96        25\n",
      "         11       1.00      0.95      0.97        75\n",
      "\n",
      "avg / total       0.97      0.97      0.97      1748\n",
      " \n",
      "\n",
      "Returning test report:\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.93      0.89      0.91        72\n",
      "          2       0.93      0.84      0.88        50\n",
      "          3       0.68      0.68      0.68        40\n",
      "          4       0.60      0.64      0.62        44\n",
      "          5       0.94      0.96      0.95       406\n",
      "          6       0.90      1.00      0.95        27\n",
      "          7       0.91      0.48      0.62        21\n",
      "          8       0.70      0.90      0.79        42\n",
      "          9       1.00      0.38      0.55         8\n",
      "         10       1.00      0.92      0.96        12\n",
      "         11       0.93      0.89      0.91        28\n",
      "\n",
      "avg / total       0.89      0.89      0.88       750\n",
      " \n",
      "\n",
      "Other performance metrics:\n",
      "\tPercent Dependency:   The Ngram Key Selection resulted in => 40.0 of overlap (dependency) between the key words\n",
      "\tPercent None-Matches: In addition, this selection resulted in =>  0.0  percentage of Docketsheet rows without a matching Ngram \n",
      "\n"
     ]
    }
   ],
   "source": [
    "KeyNgrams = MasterFunction(\n",
    "                    \n",
    "                    TrainTestMode                  = 'Training_Mode_Known_Data',\n",
    "        \n",
    "                    stp2_FreqDist_file             = Nograms_appearance,             # In general Freq seems to perf better. \n",
    "                        stp2_Calculation_meth      = 'CalculationII_AVG_not_zero', \n",
    "                        stp2_methodology_top_words = 'Top15_highest_STDV', \n",
    "                        stp2_write2excel           = True, \n",
    "                        stp2_destination_location  = Stage2_destination_location, \n",
    "                        stp2_Ngram_type            = 'Nograms_appearance_Avg_50pct', \n",
    "\n",
    "                    stp3A_Docketsheet               = Docketsheet_train, \n",
    "                        stp3A_DirNgramLoc           = None, \n",
    "                        stp3A_Iterable              = False, \n",
    "                        stp3A_KeyPhrase             = None, \n",
    "                        stp3A_Destination_location  = None,\n",
    "                        stp3A_Transpose4mlModel     = True, \n",
    "                        stp3A_Write2Excel           = False, \n",
    "\n",
    "                    stp3B_Docketsheet               = Docketsheet_test, \n",
    "                        stp3B_DirNgramLoc           = None, \n",
    "                        stp3B_Iterable              = False, \n",
    "                        stp3B_KeyPhrase             = None, \n",
    "                        stp3B_Destination_location  = None,\n",
    "                        stp3B_Transpose4mlModel     = True, \n",
    "                        stp3B_Write2Excel           = False,\n",
    "    \n",
    "                    stp4_Max_Depth                  = 25, #25\n",
    "                        stp4_TrainTest              = 'Train', \n",
    "                        stp4_Metric                 = 'Report')    # Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Append Results to File "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a Dataframe from the predictions\n",
    "\n",
    "def create_dataframe_write2Excel(Array, Docketsheet_test):\n",
    "    \n",
    "    #os.chdir(r'/home/ccirelli2/Desktop/Docket-Sheet-Classification/Stage5_Predictions_Results')\n",
    "    \n",
    "    # Read the Docketsheet Test file into memory as a df\n",
    "    df_docketsheet = pd.read_excel(Docketsheet_test)\n",
    "    # Limit dataframe to match what was input into the ML model. \n",
    "    delimiter = [isinstance(x,str) for x in df_docketsheet['docket_text']]\n",
    "    df_limited = df_docketsheet[delimiter]\n",
    "    df_limited['Prediction'] = Array\n",
    "    \n",
    "    print(df_limited.head())\n",
    "    stp4.write_to_excel(dataframe = df_limited, \n",
    "                    location = r'/home/ccirelli2/Desktop/Docket-Sheet-Classification-DataFiles/Docketsheet_Data_04_11_18',\n",
    "                    filename = 'Step5_Prediction_Appended_Docketsheet_04.11.2018')\n",
    "    \n",
    "    return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction = create_dataframe_write2Excel(KeyNgrams, Docketsheet_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_rowlvl_2_caselvl(File):\n",
    "    # Change directory\n",
    "    os.chdir(r'/home/ccirelli2/Desktop/Docket-Sheet-Classification-DataFiles/Docketsheet_Data_04_11_18')\n",
    "    \n",
    "    # Read File into memory as a dataframe\n",
    "    df = pd.read_excel(File)\n",
    "    # Delimit dataframe\n",
    "    df_limited = df[['case_number', 'Prediction', 'activity_date']]\n",
    "    \n",
    "    # Create a Dictionary, Key = Case Number, Value = Stage. \n",
    "    Dict = {}\n",
    "    # Create a counter to identify the first row of our dataframe. \n",
    "    Count = 0\n",
    "    # Create a list to capture the stages per case. \n",
    "    List = []\n",
    "    # Iterate over each row of the dataframe. \n",
    "    for x,y in zip(df_limited.itertuples(), df_limited[1:].itertuples()):\n",
    "        # Add to our counter over each iteration. \n",
    "        Count += 1\n",
    "        # If Count == 1, append to the list the first row's prediction value. \n",
    "        if Count == 1:\n",
    "            List.append(x[2])\n",
    "        # If count > 1\n",
    "        else:\n",
    "            # If the second row case num is equal to the first row case num, keep appending the values. \n",
    "            if y[1] == x[1]:\n",
    "                List.append(y[2])\n",
    "            # At which point the next rows case number does not equal the preceding one, append the List\n",
    "            else:\n",
    "                # Create our dictiony key == case number and value == List of stages for the given case. \n",
    "                Dict[x[1]] = set(List)\n",
    "                List = []\n",
    "      \n",
    "    # Transform Dictionary \n",
    "    Dict_new = {}\n",
    "    for key in Dict.keys():\n",
    "        List = []\n",
    "        for num in range(1,12):\n",
    "            if num in Dict[key]:\n",
    "                List.append(1)\n",
    "            else:\n",
    "                List.append(0)\n",
    "        Dict_new[key] = List\n",
    "    \n",
    "    # Create Dataframe\n",
    "    df_final = pd.DataFrame(Dict_new).transpose()\n",
    "       \n",
    "    df_final = df_final.rename(index =str, columns = {0:\"Stage1\", \n",
    "                                                      1:\"Stage2\", \n",
    "                                                      2:\"Stage3\", \n",
    "                                                      3: \"Stage4\", \n",
    "                                                      4:\"Stage5\", \n",
    "                                                      5:\"Stage6\", \n",
    "                                                      6:\"Stage7\", \n",
    "                                                      7:\"Stage8\", \n",
    "                                                      8:\"Stage9\", \n",
    "                                                      9:\"Stage10\", \n",
    "                                                      10:\"Stage11\"})\n",
    "    print(df_final.head())\n",
    "    \n",
    "    stp4.write_to_excel(dataframe = df_final, \n",
    "                    location = r'/home/ccirelli2/Desktop/Docket-Sheet-Classification-DataFiles/Docketsheet_Data_04_11_18',\n",
    "                    filename = 'Case_Level_Predictions_04.11.2018')\n",
    "    \n",
    "    # Return the dictonary to the user\n",
    "    return None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed = transform_rowlvl_2_caselvl(r'Step5_Prediction_Appended_Docketsheet_04.11.2018.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
